{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Code written by Ali Babolhaveji @ 5/30/2020\n",
    "\n",
    "\n",
    "dataPath = \"../../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>url</th>\n",
       "      <th>project_id</th>\n",
       "      <th>num_frames</th>\n",
       "      <th>crowd_score</th>\n",
       "      <th>tier1</th>\n",
       "      <th>micro</th>\n",
       "      <th>nano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000.mp4</td>\n",
       "      <td>s3://drivendata-competition-clog-loss/train/10...</td>\n",
       "      <td>M</td>\n",
       "      <td>54</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001.mp4</td>\n",
       "      <td>s3://drivendata-competition-clog-loss/train/10...</td>\n",
       "      <td>F</td>\n",
       "      <td>48</td>\n",
       "      <td>0.022769</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002.mp4</td>\n",
       "      <td>s3://drivendata-competition-clog-loss/train/10...</td>\n",
       "      <td>H</td>\n",
       "      <td>122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003.mp4</td>\n",
       "      <td>s3://drivendata-competition-clog-loss/train/10...</td>\n",
       "      <td>E</td>\n",
       "      <td>55</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004.mp4</td>\n",
       "      <td>s3://drivendata-competition-clog-loss/train/10...</td>\n",
       "      <td>C</td>\n",
       "      <td>56</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573043</th>\n",
       "      <td>687207.mp4</td>\n",
       "      <td>s3://drivendata-competition-clog-loss/train/68...</td>\n",
       "      <td>G</td>\n",
       "      <td>93</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573044</th>\n",
       "      <td>687208.mp4</td>\n",
       "      <td>s3://drivendata-competition-clog-loss/train/68...</td>\n",
       "      <td>A</td>\n",
       "      <td>60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573045</th>\n",
       "      <td>687209.mp4</td>\n",
       "      <td>s3://drivendata-competition-clog-loss/train/68...</td>\n",
       "      <td>E</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573046</th>\n",
       "      <td>687210.mp4</td>\n",
       "      <td>s3://drivendata-competition-clog-loss/train/68...</td>\n",
       "      <td>D</td>\n",
       "      <td>42</td>\n",
       "      <td>0.151080</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573047</th>\n",
       "      <td>687211.mp4</td>\n",
       "      <td>s3://drivendata-competition-clog-loss/train/68...</td>\n",
       "      <td>G</td>\n",
       "      <td>61</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>573048 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename                                                url  \\\n",
       "0       100000.mp4  s3://drivendata-competition-clog-loss/train/10...   \n",
       "1       100001.mp4  s3://drivendata-competition-clog-loss/train/10...   \n",
       "2       100002.mp4  s3://drivendata-competition-clog-loss/train/10...   \n",
       "3       100003.mp4  s3://drivendata-competition-clog-loss/train/10...   \n",
       "4       100004.mp4  s3://drivendata-competition-clog-loss/train/10...   \n",
       "...            ...                                                ...   \n",
       "573043  687207.mp4  s3://drivendata-competition-clog-loss/train/68...   \n",
       "573044  687208.mp4  s3://drivendata-competition-clog-loss/train/68...   \n",
       "573045  687209.mp4  s3://drivendata-competition-clog-loss/train/68...   \n",
       "573046  687210.mp4  s3://drivendata-competition-clog-loss/train/68...   \n",
       "573047  687211.mp4  s3://drivendata-competition-clog-loss/train/68...   \n",
       "\n",
       "       project_id  num_frames  crowd_score  tier1  micro   nano  \n",
       "0               M          54     0.000000   True  False  False  \n",
       "1               F          48     0.022769  False  False  False  \n",
       "2               H         122     0.000000   True  False  False  \n",
       "3               E          55     0.000000   True  False  False  \n",
       "4               C          56     0.000000   True  False  False  \n",
       "...           ...         ...          ...    ...    ...    ...  \n",
       "573043          G          93     0.000000   True  False  False  \n",
       "573044          A          60     0.000000   True  False  False  \n",
       "573045          E          49     0.000000   True  False  False  \n",
       "573046          D          42     0.151080  False  False  False  \n",
       "573047          G          61     0.000000   True  False  False  \n",
       "\n",
       "[573048 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "metaData = os.path.join(dataPath,'train_metadata.csv')\n",
    "df = pd.DataFrame(os.listdir(os.path.join(dataPath,'video')) , columns=['vid_name'])\n",
    "pd.read_csv(metaData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils\n",
    "\n",
    "\n",
    "def getFrame( vidcap , sec , image_name ):\n",
    "        vidcap.set(cv2.CAP_PROP_POS_MSEC, sec * 1000)\n",
    "        hasFrames,image = vidcap.read()\n",
    "        if(hasFrames):\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return image ,hasFrames\n",
    "    \n",
    "\n",
    "from_sec = 0\n",
    "step = 1.\n",
    "\n",
    "vid = df.iloc[150]['vid_name']\n",
    "vidcap = cv2.VideoCapture(os.path.join(dataPath,'video',vid))\n",
    "total_frames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "frame_size = (int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH)) , int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT )))\n",
    "fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "Video_len = total_frames / fps\n",
    "time_stamp = np.linspace(from_sec , Video_len ,int(total_frames / step) )\n",
    "\n",
    "sec = 0 \n",
    "frame_num = 1\n",
    "img_cv2 , hasframe = getFrame(vidcap ,sec , frame_num)\n",
    "\n",
    "total_frames,frame_size, fps ,Video_len,time_stamp\n",
    "\n",
    "# tensor_img = np.zeros((int(total_frames) ,384,512,3))\n",
    "tensor_img = []\n",
    "for frame in range(int(total_frames)):\n",
    "    img_cv2 , hasframe = getFrame(vidcap ,time_stamp[frame] , frame)\n",
    "#     print(frame ,hasframe)\n",
    "    if hasframe:\n",
    "        tensor_img.append(img_cv2)\n",
    "#     tensor_img[frame] ,_ = getFrame(vidcap ,time_stamp[frame] , frame)\n",
    "tensor_img = np.array(list(tensor_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "scatter() got multiple values for argument 'marker'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-c60dfc6318e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# ipyvolume.quickvolshow(ds.data, lighting=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mipv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mipv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_img\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sphere\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# ipv.animation_control(s, interval=200)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# ipv.ylim(-3,3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: scatter() got multiple values for argument 'marker'"
     ]
    }
   ],
   "source": [
    "tensor_img = np.array(list(tensor_img))\n",
    "\n",
    "import ipyvolume as ipv\n",
    "# ipyvolume.examples.ball(rmax=3, rmin=2.5, shape=32, lighting=True)\n",
    "# ds = ipyvolume.datasets.aquariusA2.fetch()\n",
    "# ipyvolume.quickvolshow(ds.data, lighting=True)\n",
    "ipv.figure()\n",
    "s = ipv.scatter(*(tensor_img[:,:,:,0]), marker=\"sphere\")\n",
    "# ipv.animation_control(s, interval=200)\n",
    "# ipv.ylim(-3,3)\n",
    "# ipv.show()\n",
    "tensor_img[:,:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7617c8c86f5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_cv2\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import copy\n",
    "\n",
    "gray = cv2.cvtColor(img_cv2 , cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def plot_func(val ):\n",
    "    img_cv2 , hasframe = getFrame(vidcap ,sec , frame_num)\n",
    "    hsv = cv2.cvtColor(img_cv2,cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    lower_red = np.array([100,120,150])\n",
    "    upper_red = np.array([110,255,255])\n",
    "    mask1 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    \n",
    "#     img = Image.fromarray(img)\n",
    "#     enhancer  = ImageEnhance.Contrast(img)\n",
    "#     img = enhancer.enhance(val)\n",
    "#     enhancer  = ImageEnhance.Brightness(img)\n",
    "#     img = enhancer.enhance(val_b)\n",
    "#     img = np.hstack((hsv ,mask1))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(mask1)\n",
    "    \n",
    "interact(plot_func, val = widgets.FloatSlider(value=120,\n",
    "                                               min=0,\n",
    "                                               max=255,\n",
    "                                               step=5) )\n",
    "\n",
    "# newRet, binaryThreshold = cv2.threshold(hsv,127,255,cv2.THRESH_BINARY_INV)\n",
    "# img_gray = cv2.cvtColor(hsv, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# ret, thresh = cv2.threshold(img_gray,20,255,0)\n",
    "# contours, heirarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# cont_sort = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "# cv2.drawContours(img_cv2, cont_sort[1], -1, (0, 255, 0), 2)\n",
    "\n",
    "ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cv2 , hasframe = getFrame(vidcap ,sec , frame_num)\n",
    "hsv = cv2.cvtColor(img_cv2,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "lower_red = np.array([100,120,150])\n",
    "upper_red = np.array([110,255,255])\n",
    "mask1 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "#     img = Image.fromarray(img)\n",
    "#     enhancer  = ImageEnhance.Contrast(img)\n",
    "#     img = enhancer.enhance(val)\n",
    "#     enhancer  = ImageEnhance.Brightness(img)\n",
    "#     img = enhancer.enhance(val_b)\n",
    "#     img = np.hstack((hsv ,mask1))\n",
    "\n",
    "mask_ind = np.where(mask1>0)\n",
    "max(mask_ind[0])\n",
    "\n",
    "xmin , xmax = min(mask_ind[1]) , max(mask_ind[1])\n",
    "ymin , ymax = min(mask_ind[0]) , max(mask_ind[0])\n",
    "\n",
    "img_cv2 =  cv2.rectangle(img_cv2 , (xmin,ymin) ,(xmax,ymax),(255,0,0),1,1)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_cv2 = cv2.GaussianBlur(img_cv2, (5, 5), 0)\n",
    "# img_cv2 = cv2.Canny (img_cv2, 50, 100)\n",
    "# img_cv2 = cv2.dilate(img_cv2, None, iterations=2)\n",
    "# img_cv2 = cv2.erode (img_cv2, None, iterations=1)\n",
    "img_gray = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(img_gray,20,255,0)\n",
    "contours, heirarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cont_sort = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "cv2.drawContours(img_cv2, cont_sort[2], -1, (0, 255, 0), 2)\n",
    "# cv2.drawContours(img_cv2, contours, -1, (127,127,0), 2)\n",
    "\n",
    "# cnts = cnts[0] if imutils.is_cv2() else cnts[1]\n",
    "# cnts\n",
    "# c = max(cnts, key=cv2.contourArea)\n",
    "hsv = cv2.cvtColor(img_cv2,cv2.COLOR_BGR2HSV)\n",
    "lower_red = np.array([170,120,70])\n",
    "upper_red = np.array([180,255,255])\n",
    "mask1 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "plt.imshow(mask1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
