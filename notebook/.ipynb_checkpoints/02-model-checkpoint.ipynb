{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'EfficientNet3D' from 'lib' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f46042846299>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#from torchsummary import summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEfficientNet3D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'EfficientNet3D' from 'lib' (unknown location)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "package_path = '../'\n",
    "# package_path = '../../script2/Result/nuScenes/exp3/sources/'\n",
    "\n",
    "if not package_path in sys.path:\n",
    "    sys.path.append(package_path)\n",
    "\n",
    "import torch\n",
    "#from torchsummary import summary\n",
    "from lib import EfficientNet3D\n",
    "from lib.\n",
    "\n",
    "\n",
    "def init_params(m):\n",
    "    if type(m)==nn.Linear or type(m)==nn.Conv2d:\n",
    "        m.weight.data=torch.randn(m.weight.size())*.01#Random weight initialisation\n",
    "        m.bias.data=torch.zeros(m.bias.size())\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_uniform(m.weight.data)\n",
    "        nn.init.xavier_uniform(m.bias.data)\n",
    "\n",
    "class my_deep_fake_EfficientNet(nn.Module):\n",
    "    def __init__(self,in_channels=3 ):\n",
    "        super(my_deep_fake_EfficientNet, self).__init__()\n",
    "        self.backend = EfficientNet3D.from_name(\"efficientnet-b7\", override_params={'num_classes': 2}, in_channels = in_channels)\n",
    "        \n",
    "        #print(self.backend)\n",
    "        print(\"************Create RNN**************\")\n",
    "        # Create RNN\n",
    "        input_dim = 256    # input dimension\n",
    "        hidden_dim = 100  # hidden layer dimension\n",
    "        layer_dim = 2     # number of hidden layers\n",
    "        output_dim = 32   # output dimension\n",
    "        \n",
    "        self.rnn = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    " \n",
    "        \n",
    "        \n",
    "\n",
    "        #opt.landmarks = True\n",
    "        #self.model_landmarks = generate_model(opt)\n",
    "\n",
    "        for param in self.backend.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        #for param in self.model_landmarks.parameters():\n",
    "            #param.requires_grad = False\n",
    "\n",
    "        self.decode_to_Fake_True =  nn.Sequential(\n",
    " #           torch.nn.Linear(1280, 1024), #b0\n",
    " #           torch.nn.Linear(1280, 1024), #b1\n",
    " #           torch.nn.Linear(1408, 1024), #b2\n",
    " #           torch.nn.Linear(1536, 1024), #b3\n",
    " #           torch.nn.Linear(1792, 1024), #b4\n",
    " #           torch.nn.Linear(2048, 1024), #b5\n",
    " #           torch.nn.Linear(2304, 1024), #b6\n",
    "            torch.nn.Linear(2560, 512), #b7\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(p=.25),\n",
    "    #        torch.nn.Linear(1024, 512+256),\n",
    "    #        torch.nn.ReLU(inplace=True),\n",
    "     #       torch.nn.Dropout(p=.25), \n",
    "     #       torch.nn.Linear(512+256, 512),\n",
    "     #       torch.nn.ReLU(inplace=True),\n",
    "     #       torch.nn.Dropout(p=.25), \n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.ReLU(inplace=True))\n",
    "\n",
    "         \n",
    "        self.head=  nn.Sequential(\n",
    "          #  torch.nn.Dropout(p=.25), \n",
    "            torch.nn.Linear(32+256, 32),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(p=.25),\n",
    "            torch.nn.Linear(32, 2),\n",
    "            torch.nn.Sigmoid())\n",
    "\n",
    "        self.head.apply(weights_init)\n",
    "        self.decode_to_Fake_True.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print('input--------------------' ,x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backend(x) \n",
    "        x1= x.view(batch_size,-1,256) \n",
    "       # print('backend--------------------' ,x.shape  , x1.shape)\n",
    "        x2 = self.decode_to_Fake_True(x) #256\n",
    "       # print('decode_to_Fake_True--------------------' ,x.shape)\n",
    "        x = self.rnn(x1)\n",
    "        #print('cattt--------------------' ,x.shape ,x2.shape)\n",
    "        x = torch.cat((x, x2), 1)\n",
    "        #print('rnn--------------------' ,x.shape)\n",
    "        x = self.head(x)\n",
    "        # input_ = x.t()* 1000\n",
    "        # input_ = input_.long()\n",
    "        # print('transpose--------------------' ,input_.shape)\n",
    "        # embeded = self.embedding(input_ )\n",
    "        # print('embeded--------------------' ,embeded.shape)\n",
    "        # print('embeded' , embeded.shape)\n",
    "        # hidden = torch.zeros((256,batch_size,256) ,requires_grad=True)\n",
    "        # x = self.LSTM (embeded  )\n",
    "        # print('LSTM' , embeded.shape)\n",
    "        #print('out--------------------' ,x.shape)\n",
    "       \n",
    "\n",
    "\n",
    "        return x\n",
    "        \n",
    "        \n",
    "# Create RNN Model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, \n",
    "                          nonlinearity='relu')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros((self.layer_dim, x.size(0), self.hidden_dim),requires_grad=True).cuda()\n",
    "            \n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\": \n",
    "    model = my_deep_fake_EfficientNet()\n",
    "    model.to(device)\n",
    "    inputs = torch.randn((1, 1, 300, 256, 256)).to(device)\n",
    "    model(inputs).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
