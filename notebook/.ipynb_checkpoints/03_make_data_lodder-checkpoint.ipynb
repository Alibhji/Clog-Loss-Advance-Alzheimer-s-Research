{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['credentials.yml', 'train_labels.csv', 'train_metadata.csv', 'video']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "\n",
    "config = './config.yml'\n",
    "with open (config , 'rb') as f:\n",
    "    config = yaml.load(f ,Loader=yaml.FullLoader)\n",
    "    \n",
    "os.listdir(config['dataset']['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "import ipyvolume as ipv\n",
    "from boto3.session import Session\n",
    "import boto3\n",
    "\n",
    "class ClogLossDataset(Dataset):\n",
    "    def __init__(self, config , split = 'train' , type ='train' , online_data= True ):\n",
    "        self.cfg = config\n",
    "        self.dataPath = config['dataset']['path']\n",
    "        self.videoPath = os.path.join(config['dataset']['path'], 'video')\n",
    "        self.online_data = online_data\n",
    "        df = pd.DataFrame([file for file in os.listdir(self.videoPath)  if file.split('.')[-1] == 'mp4'], columns=['filename'])\n",
    "        metaData = os.path.join(self.dataPath ,'train_metadata.csv')\n",
    "        metaData = pd.read_csv(metaData)\n",
    "        \n",
    "        label = os.path.join(self.dataPath ,'train_labels.csv')\n",
    "        label = pd.read_csv(label)\n",
    "        \n",
    "        self.df_dataset = metaData\n",
    "        self.df_dataset['stalled'] =label['stalled']\n",
    "        \n",
    "#         self.df_dataset = metaData[metaData['filename'].isin(df['filename'])]\n",
    "#         self.df_dataset['stalled'] =label[label['filename'].isin(df['filename'])]['stalled']\n",
    "        self.df_dataset['vid_id'] = self.df_dataset.index\n",
    "        \n",
    "        \n",
    "        if True:\n",
    "            self.download_fldr = 'downloded_data' \n",
    "            self.download_fldr = os.path.join(self.dataPath ,self.download_fldr )\n",
    "            if not os.path.exists(f\"./{self.download_fldr}\"):\n",
    "                os.mkdir(self.download_fldr)\n",
    "            credentials_path = config['dataset']['credentials_path']\n",
    "            with open (credentials_path , 'rb') as f:\n",
    "                credentials = yaml.load(f ,Loader=yaml.FullLoader)\n",
    "#                 print(credentials)\n",
    "\n",
    "            ACCESS_KEY = credentials['ACCESS_KEY']\n",
    "            SECRET_KEY = credentials['SECRET_KEY']\n",
    "\n",
    "            session = Session(aws_access_key_id=ACCESS_KEY,\n",
    "                          aws_secret_access_key=SECRET_KEY)\n",
    "            s3 = session.resource('s3')\n",
    "            self.bucket = s3.Bucket('drivendata-competition-clog-loss')\n",
    "\n",
    "#             for s3_file in your_bucket.objects.all():\n",
    "#                 print(s3_file.key) # prints the contents of bucket\n",
    "                \n",
    "        else:\n",
    "            self.df_dataset = self.df_dataset[metaData['filename'].isin(df['filename'])]\n",
    "            self.df_dataset = self.df_dataset.reset_index(drop = True)\n",
    "                \n",
    "    \n",
    "        \n",
    "#         self.df_dataset['num_frames'].plot.hist()\n",
    "#         self.df_dataset['stalled'] = label[label['filename'].isin(df['filename'])]\n",
    "        \n",
    "#         print((label.iloc[570501]))\n",
    "#         print((self.df_dataset))\n",
    "        \n",
    "    def getFrame( self , vidcap , sec , image_name ):\n",
    "        vidcap.set(cv2.CAP_PROP_POS_MSEC, sec * 1000)\n",
    "        hasFrames,image = vidcap.read()\n",
    "        if(hasFrames):\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return image ,hasFrames\n",
    "    \n",
    "    def get_specified_area(self , image):\n",
    "    \n",
    "        # convert to hsv to detect the outlined orange area\n",
    "        hsv = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "        lower_red = np.array([100,120,150])\n",
    "        upper_red = np.array([110,255,255])\n",
    "        # create a mask\n",
    "        mask1 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "        mask1 = cv2.dilate(mask1, None, iterations=2)\n",
    "        mask_ind = np.where(mask1>0)\n",
    "        xmin , xmax = min(mask_ind[1]) , max(mask_ind[1])\n",
    "        ymin , ymax = min(mask_ind[0]) , max(mask_ind[0])\n",
    "        # remove orange line from the image\n",
    "\n",
    "\n",
    "        return mask1 ,(xmin , xmax , ymin , ymax)\n",
    "\n",
    "    def filter_image(self, image ,mask1 ,area):\n",
    "        xmin , xmax,ymin , ymax = area\n",
    "        \n",
    "        mask_ind = np.where(mask1>0)\n",
    "        image[mask_ind ]=0,0,0\n",
    "        # fill the area to skip the data outside of this area\n",
    "        ret,mask1 = cv2.threshold(mask1,10,255,cv2.THRESH_BINARY_INV)\n",
    "        contours,hierarchy = cv2.findContours(mask1, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        contours = [ctr for ctr in contours if cv2.contourArea(ctr) < 5*(mask1.shape[0]*mask1.shape[1])/6]\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "#         print(len(contours))\n",
    "        cv2.drawContours(mask1, [contours[-1]], -1, (0, 0, 0), -1)\n",
    "        # remove data out of the outlined area\n",
    "        image[mask1>0] = (0,0,0)\n",
    "        \n",
    "    #     image =  cv2.rectangle(image , (xmin,ymin) ,(xmax,ymax),(255,255,255),4,4)\n",
    "        image = image[ ymin:ymax , xmin:xmax ]\n",
    "        image = cv2.resize(image ,(150,150))\n",
    "        image = image /255.\n",
    "    #     image -= image.mean()\n",
    "    #     image /= image.std()\n",
    "    #     print(image.shape , xmin , xmax,ymin , ymax)\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def draw_tensor(tensor_img):\n",
    "\n",
    "        ipv.figure()\n",
    "        ipv.volshow(tensor_img[...,1], level=[0.41, 0.75], opacity=0.5, level_width=0.1, data_min=0, data_max=1)\n",
    "        ipv.view(-30, 40)\n",
    "        ipv.show()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df_dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df_dataset.iloc[index]\n",
    "#         print(row)\n",
    "        if self.online_data:\n",
    "            vid_p = os.path.join(self.download_fldr ,f\"{row.filename}\"\n",
    "            self.bucket.download_file(f\"train/{row.filename}\", vid_p))       \n",
    "            vidcap = cv2.VideoCapture(vid_p)\n",
    "        else:\n",
    "            vidcap = cv2.VideoCapture(os.path.join(self.videoPath,row.filename))\n",
    "        total_frames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "#         total_frames = config['dataset']['num_frames']\n",
    "        frame_size = (int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH)) , int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT )))\n",
    "        fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "        Video_len = total_frames / fps\n",
    "        from_sec = 0 \n",
    "        time_stamp = np.linspace(from_sec , Video_len , int(total_frames / 1.0) )\n",
    "    \n",
    "        tensor_img = []\n",
    "        for frame in range(int(total_frames)):\n",
    "            image , hasframe = self.getFrame(vidcap ,time_stamp[frame] , frame)\n",
    "            \n",
    "            if hasframe:\n",
    "                if frame==0:\n",
    "                    mask , area = self.get_specified_area(image)\n",
    "                image = self.filter_image(image , mask, area)\n",
    "                tensor_img.append(image)\n",
    "                \n",
    "        \n",
    "                \n",
    "        tensor_img = np.array(list(tensor_img))\n",
    "        \n",
    "        \n",
    "#         self.draw_tensor(tensor_img)\n",
    "        return tensor_img\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "train_Dataset = ClogLossDataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from  tqdm.notebook import tqdm\n",
    "\n",
    "# for i,obj in enumerate(train_Dataset):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'vidcap' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-0986b4d02ac2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#1200 has a problem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mtrain_Dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# a.shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-125-bae9c4837ba2>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[0mvidcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvideoPath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0mtotal_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvidcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAP_PROP_FRAME_COUNT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;31m#         total_frames = config['dataset']['num_frames']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mframe_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvidcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAP_PROP_FRAME_WIDTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvidcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAP_PROP_FRAME_HEIGHT\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'vidcap' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#1200 has a problem\n",
    "a =train_Dataset[10]\n",
    "# a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_img = train_Dataset[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://drivendata-competition-clog-loss/train/100109.mp4'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for img in tensor_img:\n",
    "#     print(int(img.sum()))\n",
    "train_Dataset.df_dataset['stalled'].hist()\n",
    "train_Dataset.df_dataset[train_Dataset.df_dataset['stalled']==1].head(50)\n",
    "train_Dataset.df_dataset['url'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '11660ED58CCCF402',\n",
       "  'HostId': '4pONzeSxLOfpNuhM0GsionDiE0Nv3REmhvx1X5frS8QdOqnT3tmjkbB25NAU50wh8L2yg9EGTYI=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '4pONzeSxLOfpNuhM0GsionDiE0Nv3REmhvx1X5frS8QdOqnT3tmjkbB25NAU50wh8L2yg9EGTYI=',\n",
       "   'x-amz-request-id': '11660ED58CCCF402',\n",
       "   'date': 'Mon, 01 Jun 2020 00:49:10 GMT',\n",
       "   'content-type': 'application/xml',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Buckets': [{'Name': 'awsrobomakerdeepracer-1575516562308-bundlesbucket-ccnyac42alop',\n",
       "   'CreationDate': datetime.datetime(2019, 12, 5, 3, 29, 25, tzinfo=tzutc())},\n",
       "  {'Name': 'awsrobomakerhelloworld-157551550259-bundlesbucket-1h4vuvakqkhv0',\n",
       "   'CreationDate': datetime.datetime(2019, 12, 5, 3, 11, 46, tzinfo=tzutc())},\n",
       "  {'Name': 'awsrobomakerobjecttracker-157551620-bundlesbucket-xxfytlraxkne',\n",
       "   'CreationDate': datetime.datetime(2019, 12, 5, 3, 23, 27, tzinfo=tzutc())}],\n",
       " 'Owner': {'DisplayName': 'ali.bhji',\n",
       "  'ID': 'af2df8292cf3a6832f9aec5bae845c225ae7b61a60ce142ba75a09ec77c17f0f'}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install boto3\n",
    "# import boto3\n",
    "\n",
    "# session = boto3.Session()\n",
    "\n",
    "# credentials = session.get_credentials()\n",
    "# access_key = credentials.access_key\n",
    "# secret_key = credentials.secret_key\n",
    "\n",
    "\n",
    "\n",
    "import boto3\n",
    "\n",
    "client = boto3.client('s3', aws_access_key_id='AKIAJ3GPZAGKPIC7LESQ', aws_secret_access_key='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')\n",
    "response = client.list_buckets()\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['train/100109.mp4']\n",
    "\n",
    "\n",
    "# s3.Bucket('drivendata-competition-clog-loss').download_file('train','100109.mp4')\n",
    "# os.path.basename('train/100109.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "locations = ['s3://drivendata-competition-clog-loss/train/100109.mp4']\n",
    "s3_client = boto3.client('s3',aws_access_key_id='AKIAJ3GPZAGKPIC7LESQ', aws_secret_access_key='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')\n",
    "bucket = 'drivendata-competition-clog-loss'\n",
    "prefix = 'train'\n",
    "\n",
    "# for file in locations:\n",
    "#     s3_client.download_file(bucket, 'train', '100109.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s3.Bucket.objectsCollection(s3.Bucket(name='drivendata-competition-clog-loss'), s3.ObjectSummary)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from boto3.session import Session\n",
    "import boto3\n",
    "\n",
    "ACCESS_KEY = 'AKIAJ3GPZAGKPIC7LESQ'\n",
    "SECRET_KEY = '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'\n",
    "\n",
    "session = Session(aws_access_key_id=ACCESS_KEY,\n",
    "              aws_secret_access_key=SECRET_KEY)\n",
    "s3 = session.resource('s3')\n",
    "your_bucket = s3.Bucket('drivendata-competition-clog-loss')\n",
    "\n",
    "# for s3_file in your_bucket.objects.all():\n",
    "#     print(s3_file.key) # prints the contents of bucket\n",
    "    \n",
    "# your_bucket.download_file('test/104611.mp4', '104611.mp4')\n",
    "\n",
    "# s3 = boto3.client ('s3',aws_access_key_id=ACCESS_KEY,\n",
    "#               aws_secret_access_key=SECRET_KEY)\n",
    "\n",
    "# s3.download_file(your_bucket,'train/101941.mp4','101941.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_bucket.download_file('test/104611.mp4', '104611.mp4')\n",
    "your_bucket.creation_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "files = ['train/100109.mp4']\n",
    "\n",
    "bucket = 'drivendata-competition-clog-loss'\n",
    "\n",
    "s3 = boto3.resource('s3',aws_access_key_id='AKIAJ3GPZAGKPIC7LESQ', aws_secret_access_key='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')\n",
    "\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    try:\n",
    "        a = s3.Bucket(bucket).download_file(file, os.path.basename(file))\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            print(\"The object does not exist.\")\n",
    "        else:\n",
    "            raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
