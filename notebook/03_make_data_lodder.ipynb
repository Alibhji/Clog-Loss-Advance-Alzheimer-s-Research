{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['credentials.yml',\n",
       " 'downloded_data',\n",
       " 'train_labels.csv',\n",
       " 'train_metadata.csv',\n",
       " 'video']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "\n",
    "config = './config.yml'\n",
    "with open (config , 'rb') as f:\n",
    "    config = yaml.load(f ,Loader=yaml.FullLoader)\n",
    "    \n",
    "os.listdir(config['dataset']['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "IPython.OutputArea.prototype._should_scroll = function(lines) { \n",
       "\n",
       "    return false; \n",
       "\n",
       "} \n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript \n",
    "\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) { \n",
    "\n",
    "    return false; \n",
    "\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "import ipyvolume as ipv\n",
    "from boto3.session import Session\n",
    "import boto3\n",
    "\n",
    "class ClogLossDataset(Dataset):\n",
    "    def __init__(self, config , split = 'train' , type ='train' , online_data= True ):\n",
    "        self.cfg = config\n",
    "        self.dataPath = config['dataset']['path']\n",
    "        self.videoPath = os.path.join(config['dataset']['path'], 'video')\n",
    "        self.online_data = online_data\n",
    "        \n",
    "        metaData = os.path.join(self.dataPath ,'train_metadata.csv')\n",
    "        metaData = pd.read_csv(metaData)\n",
    "        \n",
    "        label = os.path.join(self.dataPath ,'train_labels.csv')\n",
    "        label = pd.read_csv(label)\n",
    "        \n",
    "        self.df_dataset = metaData\n",
    "        self.df_dataset['stalled'] =label['stalled']\n",
    "        \n",
    "#         self.df_dataset = metaData[metaData['filename'].isin(df['filename'])]\n",
    "#         self.df_dataset['stalled'] =label[label['filename'].isin(df['filename'])]['stalled']\n",
    "        self.df_dataset['vid_id'] = self.df_dataset.index\n",
    "        \n",
    "        \n",
    "        if True:\n",
    "            self.download_fldr = 'downloded_data' \n",
    "            self.download_fldr = os.path.join(self.dataPath ,self.download_fldr )\n",
    "            if not os.path.exists(f\"./{self.download_fldr}\"):\n",
    "                os.mkdir(self.download_fldr)\n",
    "            credentials_path = config['dataset']['credentials_path']\n",
    "            with open (credentials_path , 'rb') as f:\n",
    "                credentials = yaml.load(f ,Loader=yaml.FullLoader)\n",
    "#                 print(credentials)\n",
    "\n",
    "            ACCESS_KEY = credentials['ACCESS_KEY']\n",
    "            SECRET_KEY = credentials['SECRET_KEY']\n",
    "\n",
    "            session = Session(aws_access_key_id=ACCESS_KEY,\n",
    "                          aws_secret_access_key=SECRET_KEY)\n",
    "            s3 = session.resource('s3')\n",
    "            self.bucket = s3.Bucket('drivendata-competition-clog-loss')\n",
    "#             self.df_dataset = self.df_dataset[self.df_dataset['num_frames'] > 200]\n",
    "#             train_Dataset.df_dataset[train_Dataset.df_dataset['tier1']== True]\n",
    "            \n",
    "#             self.df_dataset = self.df_dataset[self.df_dataset['stalled']==0]\n",
    "\n",
    "#             for s3_file in your_bucket.objects.all():\n",
    "#                 print(s3_file.key) # prints the contents of bucket\n",
    "                \n",
    "        else:\n",
    "            df = pd.DataFrame([file for file in os.listdir(self.videoPath)  if file.split('.')[-1] == 'mp4'], columns=['filename'])\n",
    "            self.df_dataset = self.df_dataset[metaData['filename'].isin(df['filename'])]\n",
    "            self.df_dataset = self.df_dataset.reset_index(drop = True)\n",
    "                \n",
    "    \n",
    "        \n",
    "#         self.df_dataset['num_frames'].plot.hist()\n",
    "#         self.df_dataset['stalled'] = label[label['filename'].isin(df['filename'])]\n",
    "        \n",
    "#         print((label.iloc[570501]))\n",
    "#         print((self.df_dataset))\n",
    "        \n",
    "    def getFrame( self , vidcap , sec , image_name ):\n",
    "        vidcap.set(cv2.CAP_PROP_POS_MSEC, sec * 1000)\n",
    "        hasFrames,image = vidcap.read()\n",
    "        if(hasFrames):\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return image ,hasFrames\n",
    "    \n",
    "    def get_specified_area(self , image):\n",
    "    \n",
    "        # convert to hsv to detect the outlined orange area\n",
    "        hsv = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "        lower_red = np.array([100,120,150])\n",
    "        upper_red = np.array([110,255,255])\n",
    "        # create a mask\n",
    "        mask1 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "        mask1 = cv2.dilate(mask1, None, iterations=2)\n",
    "        mask_ind = np.where(mask1>0)\n",
    "        xmin , xmax = min(mask_ind[1]) , max(mask_ind[1])\n",
    "        ymin , ymax = min(mask_ind[0]) , max(mask_ind[0])\n",
    "        # remove orange line from the image\n",
    "\n",
    "\n",
    "        return mask1 ,(xmin , xmax , ymin , ymax)\n",
    "\n",
    "    def filter_image(self, image ,mask1 ,area):\n",
    "        xmin , xmax,ymin , ymax = area\n",
    "        \n",
    "        mask_ind = np.where(mask1>0)\n",
    "        image[mask_ind ]=0,0,0\n",
    "        # fill the area to skip the data outside of this area\n",
    "        ret,mask1 = cv2.threshold(mask1,10,255,cv2.THRESH_BINARY_INV)\n",
    "        contours,hierarchy = cv2.findContours(mask1, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        contours = [ctr for ctr in contours if cv2.contourArea(ctr) < 5*(mask1.shape[0]*mask1.shape[1])/6]\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "#         print(len(contours))\n",
    "        cv2.drawContours(mask1, [contours[-1]], -1, (0, 0, 0), -1)\n",
    "        # remove data out of the outlined area\n",
    "        image[mask1>0] = (0,0,0)\n",
    "        \n",
    "    #     image =  cv2.rectangle(image , (xmin,ymin) ,(xmax,ymax),(255,255,255),4,4)\n",
    "        image = image[ ymin:ymax , xmin:xmax ]\n",
    "        image = cv2.resize(image ,(150,150))\n",
    "        image = image /255.\n",
    "    #     image -= image.mean()\n",
    "    #     image /= image.std()\n",
    "    #     print(image.shape , xmin , xmax,ymin , ymax)\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def draw_tensor(tensor_img):\n",
    "\n",
    "        ipv.figure()\n",
    "        ipv.volshow(tensor_img[...,0], level=[0.36, 0.55,1], opacity=[0.11,0.13, 0.13], level_width=0.05, data_min=0, data_max=1 ,lighting=True)\n",
    "        ipv.view(-30, 45)\n",
    "        ipv.show()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df_dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df_dataset.iloc[index]\n",
    "#         print(row)\n",
    "        if self.online_data:\n",
    "            vid_p = os.path.join(self.download_fldr ,f\"{row.filename}\")\n",
    "            self.bucket.download_file(f\"train/{row.filename}\",vid_p )       \n",
    "            vidcap = cv2.VideoCapture(vid_p)\n",
    "#             \n",
    "        else:\n",
    "            vidcap = cv2.VideoCapture(os.path.join(self.videoPath,row.filename))\n",
    "        total_frames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "#         total_frames = config['dataset']['num_frames']\n",
    "        frame_size = (int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH)) , int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT )))\n",
    "        fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "        Video_len = total_frames / fps\n",
    "        from_sec = 0 \n",
    "        time_stamp = np.linspace(from_sec , Video_len , int(total_frames / 1.0) )\n",
    "    \n",
    "        tensor_img = []\n",
    "        \n",
    "        for frame in range(int(total_frames)):\n",
    "            image , hasframe = self.getFrame(vidcap ,time_stamp[frame] , frame)\n",
    "            \n",
    "            if hasframe:\n",
    "                if frame==0:\n",
    "                    mask , area = self.get_specified_area(image)\n",
    "                image = self.filter_image(image , mask, area)\n",
    "                tensor_img.append(image)\n",
    "                \n",
    "            if frame >= 199:\n",
    "                break\n",
    "            \n",
    "            \n",
    "        if  len(tensor_img) < 200:\n",
    "            for kk in range(200 - len(tensor_img) ):\n",
    "                tensor_img.append(list(np.zeros([150,150,3])))\n",
    "                \n",
    "        print(len(tensor_img))\n",
    "        vidcap.release()  \n",
    "        os.remove(vid_p)\n",
    "        tensor_img = np.array(list(tensor_img))\n",
    "        print(tensor_img.shape)\n",
    "        \n",
    "       \n",
    "            \n",
    "        \n",
    "#         self.draw_tensor(tensor_img)\n",
    "#         print(row)\n",
    "        tensor_img = np.moveaxis(tensor_img,3,0)\n",
    "        return tensor_img\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "train_Dataset = ClogLossDataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         54\n",
       "1         48\n",
       "3         55\n",
       "4         56\n",
       "5         26\n",
       "          ..\n",
       "573043    93\n",
       "573044    60\n",
       "573045    49\n",
       "573046    42\n",
       "573047    61\n",
       "Name: num_frames, Length: 550830, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from  tqdm.notebook import tqdm\n",
    "\n",
    "# for i,obj in enumerate(train_Dataset):\n",
    "#     print(i)\n",
    "train_Dataset.df_dataset[train_Dataset.df_dataset['num_frames'] < 200]['num_frames'].hist()\n",
    "train_Dataset.df_dataset[train_Dataset.df_dataset['num_frames'] < 100]['num_frames']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "(200, 150, 150, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 200, 150, 150)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1200 has a problem\n",
    "a = train_Dataset[300]\n",
    "# a = np.moveaxis(a,-1,0)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 150, 3, 150)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.moveaxis(a,0,2)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-82833a10a6f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtensor_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_Dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vv' is not defined"
     ]
    }
   ],
   "source": [
    "vv\n",
    "tensor_img = train_Dataset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img in tensor_img:\n",
    "#     print(int(img.sum()))\n",
    "train_Dataset.df_dataset['stalled'].hist()\n",
    "train_Dataset.df_dataset[train_Dataset.df_dataset['stalled']==1].head(50)\n",
    "train_Dataset.df_dataset['url'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install boto3\n",
    "# import boto3\n",
    "\n",
    "# session = boto3.Session()\n",
    "\n",
    "# credentials = session.get_credentials()\n",
    "# access_key = credentials.access_key\n",
    "# secret_key = credentials.secret_key\n",
    "\n",
    "\n",
    "\n",
    "import boto3\n",
    "\n",
    "client = boto3.client('s3', aws_access_key_id='AKIAJ3GPZAGKPIC7LESQ', aws_secret_access_key='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')\n",
    "response = client.list_buckets()\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['train/100109.mp4']\n",
    "\n",
    "\n",
    "# s3.Bucket('drivendata-competition-clog-loss').download_file('train','100109.mp4')\n",
    "# os.path.basename('train/100109.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "locations = ['s3://drivendata-competition-clog-loss/train/100109.mp4']\n",
    "s3_client = boto3.client('s3',aws_access_key_id='AKIAJ3GPZAGKPIC7LESQ', aws_secret_access_key='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')\n",
    "bucket = 'drivendata-competition-clog-loss'\n",
    "prefix = 'train'\n",
    "\n",
    "# for file in locations:\n",
    "#     s3_client.download_file(bucket, 'train', '100109.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boto3.session import Session\n",
    "import boto3\n",
    "\n",
    "ACCESS_KEY = 'AKIAJ3GPZAGKPIC7LESQ'\n",
    "SECRET_KEY = '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'\n",
    "\n",
    "session = Session(aws_access_key_id=ACCESS_KEY,\n",
    "              aws_secret_access_key=SECRET_KEY)\n",
    "s3 = session.resource('s3')\n",
    "your_bucket = s3.Bucket('drivendata-competition-clog-loss')\n",
    "\n",
    "# for s3_file in your_bucket.objects.all():\n",
    "#     print(s3_file.key) # prints the contents of bucket\n",
    "    \n",
    "# your_bucket.download_file('test/104611.mp4', '104611.mp4')\n",
    "\n",
    "# s3 = boto3.client ('s3',aws_access_key_id=ACCESS_KEY,\n",
    "#               aws_secret_access_key=SECRET_KEY)\n",
    "\n",
    "# s3.download_file(your_bucket,'train/101941.mp4','101941.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_bucket.download_file('test/104611.mp4', '104611.mp4')\n",
    "your_bucket.creation_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "files = ['train/100109.mp4']\n",
    "\n",
    "bucket = 'drivendata-competition-clog-loss'\n",
    "\n",
    "s3 = boto3.resource('s3',aws_access_key_id='AKIAJ3GPZAGKPIC7LESQ', aws_secret_access_key='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')\n",
    "\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    try:\n",
    "        a = s3.Bucket(bucket).download_file(file, os.path.basename(file))\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            print(\"The object does not exist.\")\n",
    "        else:\n",
    "            raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
