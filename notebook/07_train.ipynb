{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The Code written by Ali Babolhaveji @ 6/7/2020\n",
    "import sys\n",
    "import os\n",
    "\n",
    "package_path = '../'\n",
    "if not package_path in sys.path:\n",
    "    sys.path.append(package_path)\n",
    "\n",
    "import shutil, errno\n",
    "import yaml\n",
    "\n",
    "from lib import  ClogLossDataset_from_compressed_data\n",
    "from torch.utils.data import DataLoader\n",
    "from lib import  my_deep_clag_loss\n",
    "from lib import  train_val\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gc\n",
    "\n",
    "with open ('../script/config.yml', 'r') as file:\n",
    "    cfg = yaml.safe_load(file)\n",
    "    \n",
    "train_dataset = ClogLossDataset_from_compressed_data(cfg , split='train')\n",
    "val_dataset   = ClogLossDataset_from_compressed_data(cfg , split='val')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lib import create_new_experiment\n",
    "\n",
    "# this_expr = create_new_experiment(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 1000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset) , len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=cfg['train']['trainBatchSize'],\n",
    "                          num_workers=cfg['train']['num_Workers'], shuffle=True , pin_memory=True)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=cfg['train']['valBatchSize'], num_workers=cfg['train']['num_Workers'],\n",
    "                        shuffle=True ,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor , meta = next(iter(train_loader))\n",
    "\n",
    "img_tensor = img_tensor.to(device)\n",
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_deep_clag_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "#     inputs = torch.randn((2, 3, 200, 150, 150)).to(device)\n",
    "output = model(img_tensor)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows = range(len(meta['stalled']))\n",
    "oneHotLabel = torch.zeros(len(meta['stalled']),2)\n",
    "oneHotLabel[rows ,meta['stalled'].numpy()==1] =1\n",
    "oneHotLabel ,(meta['stalled'])\n",
    "\n",
    "oneHotLabel = oneHotLabel.to(device)\n",
    "\n",
    "criterion(output , oneHotLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg['model']['load']['flag']:\n",
    "    state_dict = torch.load(cfg['model']['load']['path'])\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(f\"[info] Model is loaded. [from {cfg['model']['load']['path']}]\")\n",
    "    Logger(f\"Load check point: {cfg['model']['load']['path']} \" ,logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg['train']['lr']['init'], weight_decay=1e-5)\n",
    "# criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(cfg['train']['startEpoch'], cfg['train']['endEpoch']):  # loop over the dataset multiple times\n",
    "    print(f\"=======================  Epoch {epoch} / {cfg['train']['endEpoch']}  =======================\")\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "    _, history=train_val(model, \n",
    "                         train_loader, \n",
    "                         epoch, device, \n",
    "                         optimizer, \n",
    "                         criterion, \n",
    "                         cfg, mode='train')\n",
    "    \n",
    "    \n",
    "    _, history=train_val(model, \n",
    "                         val_loader, \n",
    "                         epoch, device, \n",
    "                         optimizer, \n",
    "                         criterion, \n",
    "                         cfg, mode='val')\n",
    "\n",
    "\n",
    "\n",
    "#     # curr_val_loss, history = train_val(model,\n",
    "#     curr_val_loss, history =train_val(model,\n",
    "#                                        val_loader,\n",
    "#                                        criterion=criterion,\n",
    "#                                        epoch=epoch,\n",
    "#                                        device=device,\n",
    "#                                        optimizer=optimizer,\n",
    "#                                        writer=writer,\n",
    "#                                        history=history,\n",
    "#                                        config=cfg,\n",
    "#                                        logger=logger,\n",
    "#                                        mode='val')\n",
    "\n",
    "#     with open(os.path.join(source_save_dir, f'history.pkl'), 'wb') as handle:\n",
    "#         pickle.dump(history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#     #\n",
    "\n",
    "#     #\n",
    "#     # for name, param in model.named_parameters():\n",
    "#     #     writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
    "#     # writer.close()\n",
    "#     print('curr_val_loss', curr_val_loss)\n",
    "#     Logger(f\"curr_val_loss : {curr_val_loss}\" ,logger)\n",
    "#     #\n",
    "\n",
    "#     if curr_val_loss < best_loss:\n",
    "#         model_save_format = f\"model_E{epoch:03d}_Loss{curr_val_loss:.6f}.pt\"\n",
    "#         # torch.save(model.state_dict(), os.path.join(experiment_name ,f\"./model_E{epoch:03d}_Loss{curr_val_loss:.6f}.pt\"))\n",
    "#         torch.save(model.state_dict(), os.path.join(model_save_dir, model_save_format))\n",
    "#         # print (f\"./model_E{epoch:03d}_Loss{curr_val_loss:.6f}.pt  is saved.\")\n",
    "#         print(os.path.join(model_save_dir, model_save_format) + \" is saved.\")\n",
    "#         Logger(f\"{os.path.join(model_save_dir, model_save_format)} is saved.\" ,logger)\n",
    "#         best_loss = curr_val_loss\n",
    "#         with open(os.path.join(model_save_dir, f'history.pkl'), 'wb') as handle:\n",
    "#             pickle.dump(history, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
