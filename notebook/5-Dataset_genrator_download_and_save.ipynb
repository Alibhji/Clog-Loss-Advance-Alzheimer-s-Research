{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['credentials.yml',\n",
       " 'downloded_data',\n",
       " 'generated_Tensors',\n",
       " 'train_labels.csv',\n",
       " 'train_metadata.csv',\n",
       " 'video']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "import pandas as pd\n",
    "from boto3.session import Session\n",
    "import cv2\n",
    "import numpy as np\n",
    "import ipyvolume as ipv\n",
    "import joblib # joblib version: 0.9.4\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "config = './config.yml'\n",
    "with open (config , 'rb') as f:\n",
    "    config = yaml.load(f ,Loader=yaml.FullLoader)\n",
    "    \n",
    "os.listdir(config['dataset']['path'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClogLossDataset_downloader:\n",
    "    def __init__(self, config , online_data= True , draw_3d = False ):\n",
    "        self.cfg = config\n",
    "        self.dataPath = config['dataset']['path']\n",
    "        self.videoPath = os.path.join(config['dataset']['path'], 'video')\n",
    "        self.online_data = online_data\n",
    "        self.remove = config['dataset']['remove_donloaded_video']\n",
    "        self.draw_3d = draw_3d\n",
    "        self.saveDatasetDir  = config['dataset']['save_dir']\n",
    "        \n",
    "        if not os.path.exists(self.saveDatasetDir):\n",
    "            os.makedirs(self.saveDatasetDir)\n",
    "        \n",
    "        metaData = os.path.join(self.dataPath ,'train_metadata.csv')\n",
    "        metaData = pd.read_csv(metaData)\n",
    "        \n",
    "        label = os.path.join(self.dataPath ,'train_labels.csv')\n",
    "        label = pd.read_csv(label)\n",
    "        \n",
    "        self.df_dataset = metaData\n",
    "        self.df_dataset['stalled'] =label['stalled']\n",
    "        \n",
    "#         self.df_dataset = metaData[metaData['filename'].isin(df['filename'])]\n",
    "#         self.df_dataset['stalled'] =label[label['filename'].isin(df['filename'])]['stalled']\n",
    "        self.df_dataset['vid_id'] = self.df_dataset.index\n",
    "        \n",
    "        \n",
    "        if True:\n",
    "            self.download_fldr = 'downloded_data' \n",
    "            self.download_fldr = os.path.join(self.dataPath ,self.download_fldr )\n",
    "            if not os.path.exists(f\"./{self.download_fldr}\"):\n",
    "                os.mkdir(self.saveDatasetDir)\n",
    "            credentials_path = config['dataset']['credentials_path']\n",
    "            with open (credentials_path , 'rb') as f:\n",
    "                credentials = yaml.load(f ,Loader=yaml.FullLoader)\n",
    "#                 print(credentials)\n",
    "\n",
    "            ACCESS_KEY = credentials['ACCESS_KEY']\n",
    "            SECRET_KEY = credentials['SECRET_KEY']\n",
    "\n",
    "            session = Session(aws_access_key_id=ACCESS_KEY,\n",
    "                          aws_secret_access_key=SECRET_KEY)\n",
    "            s3 = session.resource('s3')\n",
    "            self.bucket = s3.Bucket('drivendata-competition-clog-loss')\n",
    "#             self.df_dataset = self.df_dataset[self.df_dataset['num_frames'] > 200]\n",
    "#             train_Dataset.df_dataset[train_Dataset.df_dataset['tier1']== True]\n",
    "            \n",
    "#             self.df_dataset = self.df_dataset[self.df_dataset['stalled']==0]\n",
    "\n",
    "#             for s3_file in your_bucket.objects.all():\n",
    "#                 print(s3_file.key) # prints the contents of bucket\n",
    "                \n",
    "        else:\n",
    "            df = pd.DataFrame([file for file in os.listdir(self.videoPath)  if file.split('.')[-1] == 'mp4'], columns=['filename'])\n",
    "            self.df_dataset = self.df_dataset[metaData['filename'].isin(df['filename'])]\n",
    "            self.df_dataset = self.df_dataset.reset_index(drop = True)\n",
    "            \n",
    "        self.number_of_objec = len(self.df_dataset)\n",
    "        self.current_row=0\n",
    "        \n",
    "    def getFrame( self , vidcap , sec , image_name ):\n",
    "        vidcap.set(cv2.CAP_PROP_POS_MSEC, sec * 1000)\n",
    "        hasFrames,image = vidcap.read()\n",
    "        if(hasFrames):\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return image ,hasFrames\n",
    "    \n",
    "    def get_specified_area(self , image):\n",
    "    \n",
    "        # convert to hsv to detect the outlined orange area\n",
    "        hsv = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "        lower_red = np.array([100,120,150])\n",
    "        upper_red = np.array([110,255,255])\n",
    "        # create a mask\n",
    "        mask1 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "        mask1 = cv2.dilate(mask1, None, iterations=2)\n",
    "        mask_ind = np.where(mask1>0)\n",
    "        xmin , xmax = min(mask_ind[1]) , max(mask_ind[1])\n",
    "        ymin , ymax = min(mask_ind[0]) , max(mask_ind[0])\n",
    "        # remove orange line from the image\n",
    "        return mask1 ,(xmin , xmax , ymin , ymax)\n",
    "    \n",
    "    \n",
    "    def filter_image(self, image ,mask1 ,area):\n",
    "        xmin , xmax,ymin , ymax = area\n",
    "        \n",
    "        mask_ind = np.where(mask1>0)\n",
    "        image[mask_ind ]=0,0,0\n",
    "        # fill the area to skip the data outside of this area\n",
    "        ret,mask1 = cv2.threshold(mask1,10,255,cv2.THRESH_BINARY_INV)\n",
    "        contours,hierarchy = cv2.findContours(mask1, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        contours = [ctr for ctr in contours if cv2.contourArea(ctr) < 5*(mask1.shape[0]*mask1.shape[1])/6]\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "#         print(len(contours))\n",
    "        cv2.drawContours(mask1, [contours[-1]], -1, (0, 0, 0), -1)\n",
    "        # remove data out of the outlined area\n",
    "        image[mask1>0] = (0,0,0)\n",
    "        \n",
    "    #     image =  cv2.rectangle(image , (xmin,ymin) ,(xmax,ymax),(255,255,255),4,4)\n",
    "        image = image[ ymin:ymax , xmin:xmax ]\n",
    "        image = cv2.resize(image ,(150,150))\n",
    "        \n",
    "#         image = image /255.\n",
    "    #     image -= image.mean()\n",
    "    #     image /= image.std()\n",
    "    #     print(image.shape , xmin , xmax,ymin , ymax)\n",
    "        return image\n",
    "    \n",
    "    @staticmethod\n",
    "    def draw_tensor(tensor_img):\n",
    "\n",
    "        ipv.figure()\n",
    "        ipv.volshow(tensor_img[...,0], level=[0.36, 0.55,1], opacity=[0.11,0.13, 0.13], level_width=0.05, data_min=0, data_max=1 ,lighting=True)\n",
    "        ipv.view(-30, 45)\n",
    "        ipv.show()\n",
    "        \n",
    "    def create_metadata(self,row):\n",
    "        meta_data = {}\n",
    "        meta_data['filename'] = row.filename\n",
    "        meta_data['crowd_score'] = row.crowd_score\n",
    "        meta_data['tier1'] = row.tier1\n",
    "        meta_data['stalled'] = row.stalled\n",
    "        meta_data['vid_id'] = row.vid_id\n",
    "        meta_data['project_id'] = row.project_id\n",
    "        meta_data['num_frames'] = row.num_frames\n",
    "        return meta_data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df_dataset)-1\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df_dataset.iloc[index]\n",
    "        \n",
    "        metadata = self.create_metadata(row)\n",
    "        \n",
    "        if self.online_data:\n",
    "            vid_p = os.path.join(self.download_fldr ,f\"{row.filename}\")\n",
    "            self.bucket.download_file(f\"train/{row.filename}\",vid_p )       \n",
    "            vidcap = cv2.VideoCapture(vid_p)\n",
    "#             \n",
    "        else:\n",
    "            vidcap = cv2.VideoCapture(os.path.join(self.videoPath,row.filename))\n",
    "        total_frames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "#         total_frames = config['dataset']['num_frames']\n",
    "        frame_size = (int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH)) , int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT )))\n",
    "        fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "        Video_len = total_frames / fps\n",
    "        from_sec = 0 \n",
    "        time_stamp = np.linspace(from_sec , Video_len , int(total_frames / 1.0) )\n",
    "    \n",
    "        tensor_img = []\n",
    "        \n",
    "        for frame in range(int(total_frames)):\n",
    "            image , hasframe = self.getFrame(vidcap ,time_stamp[frame] , frame)\n",
    "            \n",
    "            if hasframe:\n",
    "                if frame==0:\n",
    "                    mask , area = self.get_specified_area(image)\n",
    "                image = self.filter_image(image , mask, area)\n",
    "                tensor_img.append(image)\n",
    "                \n",
    "            if frame >= 199:\n",
    "                break\n",
    "            \n",
    "            \n",
    "        if  len(tensor_img) < 200:\n",
    "            for kk in range(200 - len(tensor_img) ):\n",
    "                tensor_img.append(list(np.zeros([150,150,3])))\n",
    "                \n",
    "#         print(len(tensor_img))\n",
    "        vidcap.release()  \n",
    "        if self.remove:\n",
    "            os.remove(vid_p)\n",
    "        tensor_img = np.array(list(tensor_img))\n",
    "#         print(tensor_img.shape)\n",
    "        if self.draw_3d :\n",
    "            self.draw_tensor(tensor_img)\n",
    "#         print(row)\n",
    "#         tensor_img = np.moveaxis(tensor_img,3,0)\n",
    "        tensor_img = tensor_img.astype(np.uint8)\n",
    "        joblib.dump([tensor_img , metadata], os.path.join(self.saveDatasetDir ,f\"{row.filename.split('.')[0]}.lzma\"), compress=('lzma', 6))\n",
    "#         print(os.path.join(self.saveDatasetDir ,f\"{row.filename}\"))\n",
    "        \n",
    "        return [tensor_img , metadata]\n",
    "            \n",
    "            \n",
    "#         def __iter__(self):\n",
    "#             return self\n",
    "\n",
    "#         def __next__(self): # Python 2: def next(self)\n",
    "#             row = self.df_dataset.iloc[self.current_row]\n",
    "#             self.current_row +=1\n",
    "#             if self.current_row < self.number_of_objec:\n",
    "#                 return row\n",
    "#             raise StopIteration\n",
    "            \n",
    "            \n",
    "video_downloder = ClogLossDataset_downloader(config  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573047\n"
     ]
    }
   ],
   "source": [
    "print(len(video_downloder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311b20e8d4fd42b08477dfc4ff182749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=573047.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(len(video_downloder))):\n",
    "    video_downloder[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_downloder[573047]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.load('../../data/generated_Tensors/100010.lzma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def getFrame(  vidcap , sec , image_name ):\n",
    "#     vidcap.set(cv2.CAP_PROP_POS_MSEC, sec * 1000)\n",
    "#     hasFrames,image = vidcap.read()\n",
    "#     if(hasFrames):\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     return image ,hasFrames\n",
    "\n",
    "\n",
    "# vidcap = cv2.VideoCapture('./test2.avi')\n",
    "# total_frames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "# #         total_frames = config['dataset']['num_frames']\n",
    "# frame_size = (int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH)) , int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT )))\n",
    "# fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "# Video_len = total_frames / fps\n",
    "# from_sec = 0 \n",
    "# time_stamp = np.linspace(from_sec , Video_len , int(total_frames+1 / 1.0) )\n",
    "\n",
    "# tensor_img = []\n",
    "\n",
    "# for frame in range(int(total_frames)):\n",
    "#     image , hasframe = getFrame(vidcap ,time_stamp[frame] , frame)\n",
    "\n",
    "#     if hasframe:\n",
    "#         tensor_img.append(image)\n",
    "        \n",
    "# b = np.array(tensor_img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# class Counter:\n",
    "#     def __init__(self, low, high):\n",
    "#         self.current = low - 1\n",
    "#         self.high = high\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         return self\n",
    "\n",
    "#     def __next__(self): # Python 2: def next(self)\n",
    "#         self.current += 1\n",
    "#         if self.current < self.high:\n",
    "#             return self.current\n",
    "#         raise StopIteration\n",
    "\n",
    "\n",
    "# for c in Counter(3, 9):\n",
    "#     print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
